
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="author" content="Eric Zhong" />
    
    <title>OpenStack源码安装</title>
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link href="/atom.xml" rel="alternate" title="" type="application/atom+xml" />
    <link rel="stylesheet" href="/assets/themes/sext-v/css/style.css">
    <link rel="stylesheet" href="/assets/themes/sext-v/css/github.css">
    <link rel="stylesheet" href="/assets/themes/sext-v/css/fontawesome.css">
    <!--[if IE 7]>
    <link rel="stylesheet" href="/assets/themes/sext-v/css/fontawesome-ie7.css">
    <![endif]-->
    <script type="text/javascript" src="/assets/themes/sext-v/js/highlight.pack.js"></script>
    <script type="text/javascript">
      hljs.initHighlightingOnLoad();
    </script>
  </head>
  <body>
      <div id="main" role="main">
        <header>
          <div id="header">
            <h1><a title="Eric Zhong" class="" href="/">Eric Zhong</a></h1>
          </div>
          <nav>
            <span><a title="Archive" class="icon-list-ul" href="/archive.html"></a></span>
            <span><a title="Tags" class="icon-tags" href="/tags.html"></a></span>
            <span><a title="Blogroll" class="icon-link" href="/links.html"></a></span>
            <span><a title="Subscribe" class="icon-rss" href="/atom.xml"></a></span>
          </nav>
        </header>
        <div id="content">
        
<article>
  <section class="title">
    <h2>OpenStack源码安装 </h2>
  </section>
  <section class="meta">
  <span class="time">
    <time datetime="2013-09-04">2013-09-04</time>
  </span>
  
  <span class="tags">
    
    <a href="/tags.html#openstack" title="openstack">#openstack</a>
    
    <a href="/tags.html#cloud" title="cloud">#cloud</a>
    
  </span>
  
  </section>
  <section class="post">
  <h1>声明</h1>

<h1>安装</h1>

<h2>准备实验环境</h2>

<p>本文使用<code>Vagrant</code>虚拟机（VirtualBox的一个前端），安装<code>Ubuntu 12.04（64-bit）</code>作为实验环境</p>

<p>先在Host机上安装好<code>VirtualBox</code>和<code>Vagrant</code></p>

<p>下载虚机映象</p>

<pre><code>vagrant box add precise64 http://files.vagrantup.com/precise64.box
</code></pre>

<p>创建配置文件（自定义工作目录：openstack）</p>

<pre><code>mkdir ~/openstack
cd openstack
vagrant init precise64
</code></pre>

<p>增加如下内容到新生成的配置文件（Host机通过<code>8080</code>端口访问虚机的80端口；2G虚拟内存）</p>

<pre><code>config.vm.network :forwarded_port, guest: 80, host: 8080
config.vm.provider :virtualbox do |vb|
    vb.customize ["modifyvm", :id, "--memory", "2048"]
end
</code></pre>

<p>启动虚机并SSH登陆</p>

<pre><code>vagrant up
vagrant ssh
</code></pre>

<p>国内用户可以换更快的源</p>

<pre><code>sudo su
cat &gt; /etc/apt/sources.list &lt;&lt; EOF
deb http://mirrors.163.com/ubuntu/ precise main universe restricted multiverse
deb-src http://mirrors.163.com/ubuntu/ precise main universe restricted multiverse
deb http://mirrors.163.com/ubuntu/ precise-security universe main multiverse restricted
deb-src http://mirrors.163.com/ubuntu/ precise-security universe main multiverse restricted
deb http://mirrors.163.com/ubuntu/ precise-updates universe main multiverse restricted
deb http://mirrors.163.com/ubuntu/ precise-proposed universe main multiverse restricted
deb-src http://mirrors.163.com/ubuntu/ precise-proposed universe main multiverse restricted
deb http://mirrors.163.com/ubuntu/ precise-backports universe main multiverse restricted
deb-src http://mirrors.163.com/ubuntu/ precise-backports universe main multiverse restricted
deb-src http://mirrors.163.com/ubuntu/ precise-updates universe main multiverse restricted
EOF

apt-get update
</code></pre>

<p>安装一些基本工具</p>

<pre><code>apt-get install vim build-essential git python-dev python-setuptools python-pip libxml2-dev libxslt-dev curl
</code></pre>

<p>附：当工作未完成且需要关机时，先“保存状态后关闭”，以后再“从保存状态启动”</p>

<pre><code>vagrant suspend
vagrant up
</code></pre>

<h2>安装数据库</h2>

<pre><code>sudo apt-get install mysql-server mysql-client python-mysqldb
</code></pre>

<p>终端弹出界面，提示输入数据库的root用户密码（例如：<code>111111</code>）</p>

<h2>安装Keystone</h2>

<p>创建keystone数据库</p>

<pre><code>mysql -u root -p
create database keystone;
quit
</code></pre>

<p>获取源码</p>

<pre><code># commit 8ba9898f4271ed61b3080ec479b43e6fc1984345
git clone git://github.com/openstack/keystone.git
</code></pre>

<p>安装依赖</p>

<pre><code>cd keystone
pip install -r requirements.txt
</code></pre>

<p>安装keystone到系统</p>

<pre><code>python setup.py install
</code></pre>

<p>复制配置文件</p>

<pre><code>mkdir -p /etc/keystone
cp etc/* /etc/keystone/

cd /etc/keystone
cp keystone.conf.sample keystone.conf
</code></pre>

<p>修改<code>/etc/keystone/keystone.conf</code> (使用<code>openssl rand -hex 10</code>生成<code>token：fa9a647b8de836869722</code>随机串)</p>

<pre><code>[DEFAULT]
admin_token = fa9a647b8de836869722
public_port = 5000
admin_port = 35357
public_endpoint = http://localhost:%(public_port)s/v2.0
admin_endpoint = http://localhost:%(admin_port)s/v2.0

[sql]
# connection = sqlite:///keystone.db
connection = mysql://root:111111@localhost/keystone

[catalog]
driver = keystone.catalog.backends.sql.Catalog
# driver = keystone.catalog.backends.templated.TemplatedCatalog
# template_file = default_catalog.templates
</code></pre>

<p>初始化数据库</p>

<pre><code>keystone-manage db_sync
</code></pre>

<p>初始化证书 （参数意义：<code>chmod root:root</code>）</p>

<pre><code>keystone-manage pki_setup --keystone-user=root --keystone-group=root
</code></pre>

<p>启动keystone服务(加上<code>-d</code>参数可查看debug信息)</p>

<pre><code>keystone-all &amp;
</code></pre>

<p>设置环境变量（目前还没有账户，只能先使用<code>admin_token</code>方式验证）</p>

<pre><code>export SERVICE_TOKEN=fa9a647b8de836869722
export SERVICE_ENDPOINT=http://localhost:35357/v2.0
</code></pre>

<p>创建类型为<code>identity</code>的<code>service</code>和相应的<code>endpoint</code></p>

<pre><code>keystone service-create --name=keystone --type=identity \
--description="Keystone Identity Service"
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |    Keystone Identity Service     |
|      id     | 714af530900840ef88106765f13f1921 |
|     name    |             keystone             |
|     type    |             identity             |
+-------------+----------------------------------+

keystone endpoint-create --service_id 714af530900840ef88106765f13f1921 \
--publicurl 'http://127.0.0.1:5000/v2.0' \
--adminurl 'http://127.0.0.1:35357/v2.0' \
--internalurl 'http://127.0.0.1:5000/v2.0'

keystone endpoint-list
+----------------------------------+-----------+----------------------------+----------------------------+-----------------------------+----------------------------------+
|                id                |   region  |         publicurl          |        internalurl         |           adminurl          |            service_id            |
+----------------------------------+-----------+----------------------------+----------------------------+-----------------------------+----------------------------------+
| d28d840d4be74a778578953a1a13324f | regionOne | http://127.0.0.1:5000/v2.0 | http://127.0.0.1:5000/v2.0 | http://127.0.0.1:35357/v2.0 | 714af530900840ef88106765f13f1921 |
+----------------------------------+-----------+----------------------------+----------------------------+-----------------------------+----------------------------------+
</code></pre>

<h3>创建管理员（admin）账户</h3>

<p>创建用户、角色、租户</p>

<pre><code>keystone user-create --name admin --pass 123456
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|  email   |                                  |
| enabled  |               True               |
|    id    | 94d416d8ebf34d3e97e345afcc5a2283 |
|   name   |              admin               |
| tenantId |                                  |
+----------+----------------------------------+

keystone role-create --name admin
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|    id    | de5cdd28a71f4df2943ac617ed20695c |
|   name   |              admin               |
+----------+----------------------------------+

keystone tenant-create --name admin
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |                                  |
|   enabled   |               True               |
|      id     | 40c76f9aa1c44907aa1a68b9cd7e8034 |
|     name    |              admin               |
+-------------+----------------------------------+
</code></pre>

<p>将admin用户设置为admin角色和admin租户的成员 （参数为上面动态生成的ID）</p>

<pre><code>keystone user-role-add --user 94d416d8ebf34d3e97e345afcc5a2283 \
--role de5cdd28a71f4df2943ac617ed20695c \
--tenant_id 40c76f9aa1c44907aa1a68b9cd7e8034
</code></pre>

<p>为admin用户创建快速设置环境变量的脚本</p>

<pre><code>cat &gt; ~/keystonerc_admin &lt;&lt; EOF
export OS_USERNAME=admin
export OS_TENANT_NAME=admin
export OS_PASSWORD=123456
export OS_AUTH_URL=http://127.0.0.1:35357/v2.0/
export PS1="[\u@\h \W(keystone_admin)]\$ "
EOF
</code></pre>

<p>不再使用<code>admin_token</code>的验证方式，清除环境变量</p>

<pre><code>unset SERVICE_TOKEN
unset SERVICE_ENDPOINT
</code></pre>

<p>用admin用户测试一下 (如果keystone用<code>-d</code>参数启动，还能看到debug信息)</p>

<pre><code>. ~/keystonerc_admin

keystone user-list
+----------------------------------+-------+---------+-------+
|                id                |  name | enabled | email |
+----------------------------------+-------+---------+-------+
| 94d416d8ebf34d3e97e345afcc5a2283 | admin |   True  |       |
+----------------------------------+-------+---------+-------+
</code></pre>

<h3>创建用户账户 (可选)</h3>

<p>创建用户、角色、租户</p>

<pre><code>keystone user-create --name joe --pass 123123
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|  email   |                                  |
| enabled  |               True               |
|    id    | 770def1aa63847bb8a5d31e1df2004d5 |
|   name   |               joe                |
| tenantId |                                  |
+----------+----------------------------------+

keystone role-create --name user
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|    id    | 430f055d142649d1b02e685025b07a5b |
|   name   |               user               |
+----------+----------------------------------+

keystone tenant-create --name trial
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |                                  |
|   enabled   |               True               |
|      id     | 249d66d789d643fabc544f6d6fc9ed9f |
|     name    |              trial               |
+-------------+----------------------------------+
</code></pre>

<p>将用户joe设置为user角色和租户trial的成员</p>

<pre><code>keystone user-role-add --user 770def1aa63847bb8a5d31e1df2004d5 \
--role 430f055d142649d1b02e685025b07a5b \
--tenant_id 249d66d789d643fabc544f6d6fc9ed9f
</code></pre>

<p>为用户joe创建环境变量快速设置脚本</p>

<pre><code>cat &gt; ~/keystonerc_joe &lt;&lt; EOF
export OS_USERNAME=joe
export OS_TENANT_NAME=trial
export OS_PASSWORD=123123
export OS_AUTH_URL=http://127.0.0.1:5000/v2.0/
export PS1="[\u@\h \W(keystone_joe)]\$ "
EOF
</code></pre>

<p>测试一下（<code>keystone user-list</code>只有管理员才有权限调用，应该会报错，但是<code>keystone token-get</code>可以返回信息）</p>

<pre><code>. ~/keystonerc_joe

$ keystone user-list
2013-09-08 14:10:14.312 10936 WARNING keystone.common.wsgi [-] You are not authorized to perform the requested action, admin_required.
You are not authorized to perform the requested action, admin_required. (HTTP 403)

keystone token-get
</code></pre>

<h2>安装Swift</h2>

<p>获取源码</p>

<pre><code># commit 5964082b2cd7aa2db6bcd112a5d33939e0f68bd9
git clone git://github.com/openstack/swift.git
</code></pre>

<p>安装依赖</p>

<pre><code>cd swift
pip install -r requirements.txt
apt-get install memcached
</code></pre>

<blockquote><p>pip安装依赖时可能报错<code>error: ffi.h: No such file or directory</code>，见<code>Troubleshooting</code>部分</p></blockquote>

<p>安装swift到系统</p>

<pre><code>python setup.py install
</code></pre>

<h3>创建Ring Files</h3>

<p>Ring File包含存储设备的所有信息 （each ring will contain 2<sup>12</sup>=4096 partitions）</p>

<pre><code>mkdir -pv /etc/swift
swift-ring-builder /etc/swift/account.builder create 12 3 1
swift-ring-builder /etc/swift/container.builder create 12 3 1
swift-ring-builder /etc/swift/object.builder create 12 3 1
</code></pre>

<p>为每个Ring增加存储设备</p>

<pre><code>swift-ring-builder /etc/swift/account.builder add z1-127.0.0.1:6002/z1d1 100
swift-ring-builder /etc/swift/account.builder add z1-127.0.0.1:6002/z1d2 100
swift-ring-builder /etc/swift/account.builder add z2-127.0.0.1:6002/z2d1 100
swift-ring-builder /etc/swift/account.builder add z2-127.0.0.1:6002/z2d2 100
swift-ring-builder /etc/swift/account.builder add z3-127.0.0.1:6002/z3d1 100
swift-ring-builder /etc/swift/account.builder add z3-127.0.0.1:6002/z3d2 100

swift-ring-builder /etc/swift/container.builder add z1-127.0.0.1:6001/z1d1 100
swift-ring-builder /etc/swift/container.builder add z1-127.0.0.1:6001/z1d2 100
swift-ring-builder /etc/swift/container.builder add z2-127.0.0.1:6001/z2d1 100
swift-ring-builder /etc/swift/container.builder add z2-127.0.0.1:6001/z2d2 100
swift-ring-builder /etc/swift/container.builder add z3-127.0.0.1:6001/z3d1 100
swift-ring-builder /etc/swift/container.builder add z3-127.0.0.1:6001/z3d2 100

swift-ring-builder /etc/swift/object.builder add z1-127.0.0.1:6000/z1d1 100
swift-ring-builder /etc/swift/object.builder add z1-127.0.0.1:6000/z1d2 100
swift-ring-builder /etc/swift/object.builder add z2-127.0.0.1:6000/z2d1 100
swift-ring-builder /etc/swift/object.builder add z2-127.0.0.1:6000/z2d2 100
swift-ring-builder /etc/swift/object.builder add z3-127.0.0.1:6000/z3d1 100
swift-ring-builder /etc/swift/object.builder add z3-127.0.0.1:6000/z3d2 100
</code></pre>

<p>To distribute the partitions across the drives in the ring</p>

<pre><code>swift-ring-builder /etc/swift/account.builder rebalance
swift-ring-builder /etc/swift/container.builder rebalance
swift-ring-builder /etc/swift/object.builder rebalance
</code></pre>

<p>检查文件是否生成</p>

<pre><code>ls /etc/swift/*gz
/etc/swift/account.ring.gz  /etc/swift/container.ring.gz  /etc/swift/object.ring.gz
</code></pre>

<p>为swift创建HashKey (使用<code>openssl rand -hex 10</code>生成随机串<code>0b1b9109c1ddde4f9c4b</code>)</p>

<pre><code>cat &gt; /etc/swift/swift.conf &lt;&lt; EOF
[swift-hash]
swift_hash_path_suffix = 0b1b9109c1ddde4f9c4b
EOF

chmod 600 /etc/swift/swift.conf
</code></pre>

<h3>配置Swift Proxy</h3>

<p>增加配置文件<code>/etc/swift/proxy-server.conf</code></p>

<pre><code>tee /etc/swift/proxy-server.conf &lt;&lt;EOF
[DEFAULT]
bind_port = 8080
workers = 3
user = swift

[pipeline:main]
pipeline = healthcheck cache authtoken keystone proxy-server

[app:proxy-server]
use = egg:swift#proxy
allow_account_management = true
account_autocreate = true

[filter:cache]
use = egg:swift#memcache
memcache_servers = 127.0.0.1:11211

[filter:catch_errors]
use = egg:swift#catch_errors

[filter:healthcheck]
use = egg:swift#healthcheck

[filter:keystone]
#paste.filter_factory = keystone.middleware.swift_auth:filter_factory
use = egg:swift#keystoneauth
operator_roles = admin, SwiftOperator
is_admin = true
cache = swift.cache

[filter:authtoken]
paste.filter_factory = keystone.middleware.auth_token:filter_factory
auth_host = 127.0.0.1
auth_port = 35357
auth_protocol = http
auth_uri = http://127.0.0.1:35357
# if its defined
admin_tenant_name = admin
admin_user = admin
admin_password = 123456
EOF
</code></pre>

<p>然后</p>

<pre><code>groupadd swift
useradd -g swift swift
chown -R swift:swift /etc/swift/

LANG=en_US.utf8
service memcached start
</code></pre>

<h3>配置Keystone</h3>

<p>切换到管理员</p>

<pre><code>. ~/keystonerc_admin
</code></pre>

<p>创建用户、租户（admin角色前面已经创建）</p>

<pre><code>keystone tenant-create --name services
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |                                  |
|   enabled   |               True               |
|      id     | 750f121b2087434e91393d554a5940d4 |
|     name    |             services             |
+-------------+----------------------------------+

keystone user-create --name swift --pass 789789
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|  email   |                                  |
| enabled  |               True               |
|    id    | e981e5f5a4244456b3a3cfdb52cd9707 |
|   name   |              swift               |
| tenantId |                                  |
+----------+----------------------------------+
</code></pre>

<p>将swift用户设置为admin角色和services租户成员</p>

<pre><code>keystone role-list
+----------------------------------+----------+
|                id                |   name   |
+----------------------------------+----------+
| 9fe2ff9ee4384b1894a90878d3e92bab | _member_ |
| de5cdd28a71f4df2943ac617ed20695c |  admin   |
| 430f055d142649d1b02e685025b07a5b |   user   |
+----------------------------------+----------+

keystone user-role-add --role de5cdd28a71f4df2943ac617ed20695c \
--tenant_id 750f121b2087434e91393d554a5940d4 \
--user e981e5f5a4244456b3a3cfdb52cd9707
</code></pre>

<p>创建service和endpoint</p>

<pre><code>keystone service-create --name swift --type object-store \
--description "Swift Storage Service"
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |      Swift Storage Service       |
|      id     | c09efaf486e54266b328cad0a52752c2 |
|     name    |              swift               |
|     type    |           object-store           |
+-------------+----------------------------------+

keystone endpoint-create --service_id c09efaf486e54266b328cad0a52752c2 \
--publicurl "http://127.0.0.1:8080/v2/AUTH_\$(tenant_id)s" \
--adminurl "http://127.0.0.1:8080/v2/AUTH_\$(tenant_id)s" \
--internalurl "http://127.0.0.1:8080/v2/AUTH_\$(tenant_id)s"
+-------------+---------------------------------------------+
|   Property  |                    Value                    |
+-------------+---------------------------------------------+
|   adminurl  | http://127.0.0.1:8080/v2/AUTH_$(tenant_id)s |
|      id     |       20f2279d7b2345c38f5315ac4518f1ea      |
| internalurl | http://127.0.0.1:8080/v2/AUTH_$(tenant_id)s |
|  publicurl  | http://127.0.0.1:8080/v2/AUTH_$(tenant_id)s |
|    region   |                  regionOne                  |
|  service_id |       c09efaf486e54266b328cad0a52752c2      |
+-------------+---------------------------------------------+
</code></pre>

<p>查看一下</p>

<pre><code>keystone service-list
+----------------------------------+----------+--------------+---------------------------+
|                id                |   name   |     type     |        description        |
+----------------------------------+----------+--------------+---------------------------+
| 714af530900840ef88106765f13f1921 | keystone |   identity   | Keystone Identity Service |
| c09efaf486e54266b328cad0a52752c2 |  swift   | object-store |   Swift Storage Service   |
+----------------------------------+----------+--------------+---------------------------+

keystone endpoint-list
+----------------------------------+-----------+---------------------------------------------+---------------------------------------------+---------------------------------------------+----------------------------------+
|                id                |   region  |                  publicurl                  |                 internalurl                 |                   adminurl                  |            service_id            |
+----------------------------------+-----------+---------------------------------------------+---------------------------------------------+---------------------------------------------+----------------------------------+
| 20f2279d7b2345c38f5315ac4518f1ea | regionOne | http://127.0.0.1:8080/v2/AUTH_$(tenant_id)s | http://127.0.0.1:8080/v2/AUTH_$(tenant_id)s | http://127.0.0.1:8080/v2/AUTH_$(tenant_id)s | c09efaf486e54266b328cad0a52752c2 |
| d28d840d4be74a778578953a1a13324f | regionOne |          http://127.0.0.1:5000/v2.0         |          http://127.0.0.1:5000/v2.0         |         http://127.0.0.1:35357/v2.0         | 714af530900840ef88106765f13f1921 |
+----------------------------------+-----------+---------------------------------------------+---------------------------------------------+---------------------------------------------+----------------------------------+
</code></pre>

<h3>配置Swift Storage Nodes</h3>

<p>创建配置文件</p>

<p><code>/etc/swift/account-server.conf</code></p>

<pre><code>tee /etc/swift/account-server.conf &lt;&lt;EOF
[DEFAULT]
devices = /srv/node
bind_ip = 127.0.0.1
bind_port = 6002
mount_check = false
user = swift
log_facility = LOG_LOCAL2
workers = 3

[pipeline:main]
pipeline = account-server

[app:account-server]
use = egg:swift#account

[account-replicator]
concurrency = 1

[account-auditor]

[account-reaper]
concurrency = 1
EOF
</code></pre>

<p><code>/etc/swift/container-server.conf</code></p>

<pre><code>tee /etc/swift/container-server.conf &lt;&lt;EOF
[DEFAULT]
devices = /srv/node
bind_ip = 127.0.0.1
bind_port = 6001
mount_check = false
user = swift
log_facility = LOG_LOCAL2
workers = 3

[pipeline:main]
pipeline = container-server

[app:container-server]
use = egg:swift#container

[container-replicator]
concurrency = 1

[container-updater]
concurrency = 1

[container-auditor]

[container-sync]

EOF
</code></pre>

<p><code>/etc/swift/object-server.conf</code></p>

<pre><code>tee /etc/swift/object-server.conf &lt;&lt;EOF
[DEFAULT]
devices = /srv/node
bind_ip = 127.0.0.1
bind_port = 6000
mount_check = false
user = swift
log_facility = LOG_LOCAL2
workers = 3

[pipeline:main]
pipeline = object-server

[app:object-server]
use = egg:swift#object

[object-replicator]
concurrency = 1

[object-updater]
concurrency = 1

[object-auditor]

[object-expirer]
EOF
</code></pre>

<p><code>/etc/swift/object-expirer.conf</code></p>

<pre><code>cat &gt; /etc/swift/object-expirer.conf &lt;&lt; EOF
[DEFAULT]

[object-expirer]
interval = 300

[pipeline:main]
pipeline = catch_errors cache proxy-server

[app:proxy-server]
use = egg:swift#proxy

[filter:cache]
use = egg:swift#memcache

[filter:catch_errors]
use = egg:swift#catch_errors
EOF
</code></pre>

<p>创建和挂载loopback设备（注意：系统重启后挂载失效）</p>

<pre><code>for zone in 1 2 3 ; do
    for device in 1 2 ; do
        truncate /var/tmp/swift-device-z${zone}d${device} --size 5G
        LOOPDEVICE=$(losetup --show -f /var/tmp/swift-device-z${zone}d${device})
        mkfs.ext4 -I 1024 $LOOPDEVICE
        mkdir -p /srv/node/z${zone}d${device}
        mount -o noatime,nodiratime,nobarrier,user_xattr $LOOPDEVICE \
        /srv/node/z${zone}d${device}
    done
done

chown -R swift:swift /srv/node /etc/swift
</code></pre>

<p>启动Swift</p>

<pre><code>swift-init all start
</code></pre>

<p>注：启动时可能会报错<code>NameError: name '_' is not defined</code>，解决方案见<code>Troubleshooting</code>部分</p>

<h3>测试Swift</h3>

<pre><code>. ~/keystonerc_admin

swift list

head -c 1024 /dev/urandom &gt; data.file ; swift upload c1 data.file
head -c 1024 /dev/urandom &gt; data2.file ; swift upload c1 data2.file
head -c 1024 /dev/urandom &gt; data3.file ; swift upload c2 data3.file

$ swift list
c1
c2

$ swift list c1
data.file
data2.file

$ swift list c2
data3.file
</code></pre>

<h2>安装Glance</h2>

<p>获取源码</p>

<pre><code># commit e3328089ef8b99b6ecf66bb2e07aec59388d4afd
git clone git://github.com/openstack/glance.git

# commit cd11833cffa306516704e871fad23699e21339f3
git clone git://github.com/openstack/python-glanceclient.git 
</code></pre>

<p>安装</p>

<pre><code>cd glance
pip install -r requirements.txt
python setup.py install

cd ../python-glanceclient
pip install -r requirements.txt
python setup.py install
cd ..
</code></pre>

<p>创建数据库</p>

<pre><code>mysql -u root -p
create database glance;
quit
</code></pre>

<p>复制配置文件</p>

<pre><code>mkdir -p /etc/glance
cp glance/etc/* /etc/glance/
</code></pre>

<p>修改<code>/etc/glance/glance-api.conf</code></p>

<pre><code>[DEFAULT]
# default_store = file
default_store = swift

sql_connection = mysql://root:111111@127.0.0.1/glance

swift_store_auth_address = http://127.0.0.1:35357/v2.0/
swift_store_user = admin:admin
swift_store_key = 123456
swift_store_create_container_on_put = True

[keystone_authtoken]
admin_tenant_name = admin
admin_user = admin
admin_password = 123456

[paste_deploy]
flavor = keystone
</code></pre>

<p>修改<code>/etc/glance/glance-registry.conf</code></p>

<pre><code>[DEFAULT]
#sql_connection = sqlite:///glance.sqlite
sql_connection = mysql://root:111111@127.0.0.1/glance

[keystone_authtoken]
admin_tenant_name = admin
admin_user = admin
admin_password = 123456

[paste_deploy]
flavor = keystone
</code></pre>

<p>初始化数据库</p>

<pre><code>mkdir -p /var/log/glance
glance-manage db_sync
</code></pre>

<p>创建service和endpoint</p>

<pre><code>keystone service-create --name=glance --type=image --description="Glance Image Service"
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |       Glance Image Service       |
|      id     | c9f6e93cfd384a27bdac595be296ad4a |
|     name    |              glance              |
|     type    |              image               |
+-------------+----------------------------------+  
keystone endpoint-create --service_id c9f6e93cfd384a27bdac595be296ad4a \
--publicurl http://localhost:9292/v1 \
--adminurl http://localhost:9292/v1 \
--internalurl http://localhost:9292/v1
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
|   adminurl  |     http://localhost:9292/v1     |
|      id     | c052904b25ac44c785c9ecb4cd53507e |
| internalurl |     http://localhost:9292/v1     |
|  publicurl  |     http://localhost:9292/v1     |
|    region   |            regionOne             |
|  service_id | c9f6e93cfd384a27bdac595be296ad4a |
+-------------+----------------------------------+
</code></pre>

<p>启动服务</p>

<pre><code>glance-api --config-file /etc/glance/glance-api.conf &amp;
glance-registry --config-file /etc/glance/glance-registry.conf &amp;
</code></pre>

<p>测试一下</p>

<pre><code>. ~/keystonerc_admin

glance image-list
+----+------+-------------+------------------+------+--------+
| ID | Name | Disk Format | Container Format | Size | Status |
+----+------+-------------+------------------+------+--------+
+----+------+-------------+------------------+------+--------+
</code></pre>

<p>增加image</p>

<pre><code>wget https://launchpad.net/cirros/trunk/0.3.0/+download/cirros-0.3.0-x86_64-disk.img
glance image-create --name="Cirros 0.3.0" \
    --disk-format=qcow2 \
    --container-format bare &lt; cirros-0.3.0-x86_64-disk.img
</code></pre>

<p>查看一下</p>

<pre><code>$ glance image-list
+--------------------------------------+--------------+-------------+------------------+----------+--------+
| ID                                   | Name         | Disk Format | Container Format | Size     | Status |
+--------------------------------------+--------------+-------------+------------------+----------+--------+
| 5ef6d78b-dd3e-4575-ad52-692552f3ddd3 | Cirros 0.3.0 | qcow2       | bare             | 13147648 | active |
+--------------------------------------+--------------+-------------+------------------+----------+--------+

$ swift list
c1
c2
glance

$ swift list glance
5ef6d78b-dd3e-4575-ad52-692552f3ddd3
</code></pre>

<h2>安装Cinder</h2>

<p>获取源码</p>

<pre><code># commit 3da3a0e827ff0e099514702d7116084245f03e80
git clone https://github.com/openstack/cinder.git

# commit 728a3419c9321f057b2a5e48b77281dc37487150
git clone https://github.com/openstack/python-cinderclient.git
</code></pre>

<p>安装</p>

<pre><code>cd cinder
pip install -r requirements.txt
python setup.py  install

cd ../python-cinderclient/
pip install -r requirements.txt
python setup.py  install
cd ..

apt-get install tgt open-iscsi rabbitmq-server
</code></pre>

<p>安装配置</p>

<pre><code>cp -af cinder/etc/cinder /etc
cp /etc/cinder/cinder.conf.sample /etc/cinder/cinder.conf
</code></pre>

<p>修改<code>/etc/cinder/api-paste.ini</code></p>

<pre><code>[filter:authtoken]
admin_tenant_name = admin
admin_user = admin
admin_password = 123456
service_protocol = http
service_host = 127.0.0.1
service_port = 5000
</code></pre>

<p>修改<code>/etc/cinder/cinder.conf</code></p>

<pre><code>[DEFAULT]
rootwrap_config=/etc/cinder/rootwrap.conf
sql_connection=mysql://root:111111@127.0.0.1/cinder
api_paste_config=/etc/cinder/api-paste.ini

state_path=/var/lib/cinder
volumes_dir=$state_path/volumes

iscsi_helper=tgtadm
volume_name_template=volume-%s
volume_group=cinder-volumes
verbose=true
auth_strategy=keystone

log_file=cinder.log
log_dir=/var/log/cinder

rabbit_host=localhost
rabbit_port=5672
rabbit_userid=guest
rabbit_password=321321
rabbit_virtual_host=/
</code></pre>

<p>创建cinder数据库</p>

<pre><code>mysql -u root -p
create database cinder;
quit
</code></pre>

<p>配置RabbitMQ</p>

<pre><code>rabbitmqctl change_password guest 321321
</code></pre>

<p>配置TGT</p>

<pre><code>mkdir -p /var/lib/cinder/volumes
sh -c "echo 'include /var/lib/cinder/volumes/*' &gt;&gt; /etc/tgt/conf.d/cinder.conf"

restart tgt
</code></pre>

<p>初始化数据库</p>

<pre><code>mkdir -p /var/log/cinder
cinder-manage db sync
</code></pre>

<p>创建卷</p>

<pre><code>dd if=/dev/zero of=~/cinder-volumes bs=1 count=0 seek=2G
losetup /dev/loop6 ~/cinder-volumes
pvcreate /dev/loop6
vgcreate cinder-volumes /dev/loop6

$ pvscan
PV /dev/sda5    VG precise64        lvm2 [79.76 GiB / 0    free]
PV /dev/loop6   VG cinder-volumes   lvm2 [2.00 GiB / 2.00 GiB free]
Total: 2 [81.75 GiB] / in use: 2 [81.75 GiB] / in no VG: 0 [0   ]
</code></pre>

<p>启动服务</p>

<pre><code>cinder-volume --config-file=/etc/cinder/cinder.conf &amp;
cinder-api --config-file=/etc/cinder/cinder.conf &amp;
cinder-scheduler --config-file=/etc/cinder/cinder.conf &amp;
</code></pre>

<p>创建<code>service</code>和<code>endpoint</code></p>

<pre><code>keystone service-create --name=volume --type=volume --description="Nova Volume Service"
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |      Nova Volume Service         |
|      id     | 0f66c20499ca4f77990e286a3607e5aa |
|     name    |              volume              |
|     type    |              volume              |
+-------------+----------------------------------+

keystone endpoint-create --service_id=0f66c20499ca4f77990e286a3607e5aa \
                    --publicurl "http://localhost:8776/v1/\$(tenant_id)s" \
                    --adminurl "http://localhost:8776/v1/\$(tenant_id)s" \
                    --internalurl "http://localhost:8776/v1/\$(tenant_id)s"
+-------------+----------------------------------------+
|   Property  |                 Value                  |
+-------------+----------------------------------------+
|   adminurl  | http://localhost:8776/v1/$(tenant_id)s |
|      id     |    a62cb598466f411bb8f6381495994690    |
| internalurl | http://localhost:8776/v1/$(tenant_id)s |
|  publicurl  | http://localhost:8776/v1/$(tenant_id)s |
|    region   |               regionOne                |
|  service_id |    0f66c20499ca4f77990e286a3607e5aa    |
+-------------+----------------------------------------+

keystone endpoint-list
</code></pre>

<p>创建1G的volume测试一下（取名：test）</p>

<pre><code>cinder list
+----+--------+--------------+------+-------------+----------+-------------+
| ID | Status | Display Name | Size | Volume Type | Bootable | Attached to |
+----+--------+--------------+------+-------------+----------+-------------+
+----+--------+--------------+------+-------------+----------+-------------+

cinder create --display_name test 1
+---------------------+--------------------------------------+
|       Property      |                Value                 |
+---------------------+--------------------------------------+
|     attachments     |                  []                  |
|  availability_zone  |                 nova                 |
|       bootable      |                False                 |
|      created_at     |      2013-09-23T13:08:54.358719      |
| display_description |                 None                 |
|     display_name    |                 test                 |
|          id         | 7e7a503c-0f47-4a74-88a6-e4fd84a9592b |
|       metadata      |                  {}                  |
|         size        |                  1                   |
|     snapshot_id     |                 None                 |
|     source_volid    |                 None                 |
|        status       |               creating               |
|     volume_type     |                 None                 |
+---------------------+--------------------------------------+

cinder list
+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
|                  ID                  |   Status  | Display Name | Size | Volume Type | Bootable | Attached to |
+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
| 7e7a503c-0f47-4a74-88a6-e4fd84a9592b | available |     test     |  1   |     None    |  False   |             |
+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
</code></pre>

<h2>安装Nova</h2>

<p>获取源码</p>

<pre><code># commit e0b5bde35a54c6855da3639582edc68afa43d5ee
git clone git://github.com/openstack/nova.git

# commit 516586a6b8f48a912d9b3d090f2d0a95a267feb2
git clone https://github.com/openstack/python-novaclient.git

# commit 142aa4583cd0ffa11e8ebc19a52f024f1ff1b235
git clone https://github.com/kanaka/noVNC.git
</code></pre>

<p>安装源码</p>

<pre><code>cd nova
pip install -r requirements.txt
python setup.py  install
cd ..

cd python-novaclient
pip install -r requirements.txt
python setup.py  install
cd ..
</code></pre>

<p>安装依赖</p>

<pre><code>apt-get install python-libvirt guestmount bridge-utils
</code></pre>

<p>安装配置文件</p>

<pre><code>cp -af  nova/etc/nova /etc
cp /etc/nova/nova.conf.sample /etc/nova/nova.conf
</code></pre>

<h3>配置数据库</h3>

<p>创建nova的数据库</p>

<pre><code>mysql -u root -p
create database nova;
quit
</code></pre>

<h3>配置Nova</h3>

<p><code>/etc/nova/nova.conf</code> 全部配置如下：</p>

<pre><code># LOGS/STATE
verbose=True
logdir=/var/log/nova
state_path=/var/lib/nova
lock_path=/var/lock/nova
rootwrap_config=/etc/nova/rootwrap.conf

# SCHEDULER
compute_scheduler_driver=nova.scheduler.filter_scheduler.FilterScheduler

# VOLUMES
volume_api_class=nova.volume.cinder.API
volume_driver=nova.volume.driver.ISCSIDriver
volume_group=cinder-volumes
volume_name_template=volume-%s
iscsi_helper=tgtadm

# DATABASE
sql_connection=mysql://root:111111@127.0.0.1/nova

# COMPUTE
libvirt_type=qemu
compute_driver=libvirt.LibvirtDriver
instance_name_template=instance-%08x
api_paste_config=/etc/nova/api-paste.ini

# COMPUTE/APIS: if you have separate configs for separate services
# this flag is required for both nova-api and nova-compute
#allow_resize_to_same_host=True

# APIS
osapi_compute_extension=nova.api.openstack.compute.contrib.standard_extensions
ec2_dmz_host=127.0.0.1
s3_host=127.0.0.1
enabled_apis=ec2,osapi_compute,metadata

# RABBITMQ
rabbit_host=localhost
rabbit_port=5672
rabbit_userid=guest
rabbit_password=321321
rabbit_virtual_host=/

# GLANCE
image_service=nova.image.glance.GlanceImageService
glance_api_servers=127.0.0.1:9292

# NETWORK
network_manager=nova.network.manager.FlatDHCPManager
force_dhcp_release=True
dhcpbridge_flagfile=/etc/nova/nova.conf
firewall_driver=nova.virt.libvirt.firewall.IptablesFirewallDriver
# Change my_ip to match each host
my_ip=127.0.0.1
public_interface=eth0
vlan_interface=eth0
flat_network_bridge=br100
flat_interface=eth0
fixed_range=192.168.100.0/24
use_ipv6=false

# NOVNC CONSOLE
novncproxy_base_url=http://127.0.0.1:6080/vnc_auto.html
# Change vncserver_proxyclient_address and vncserver_listen to match each compute host
vncserver_proxyclient_address=127.0.0.1
vncserver_listen=127.0.0.1

# AUTHENTICATION
auth_strategy=keystone
[keystone_authtoken]
auth_host = 127.0.0.1
auth_port = 35357
auth_protocol = http
admin_tenant_name = admin
admin_user = admin
admin_password = admin
signing_dirname = /tmp/keystone-signing-nova
</code></pre>

<p>修改<code>/etc/nova/api-paste.ini</code></p>

<pre><code>[filter:authtoken]
admin_tenant_name = admin
admin_user = admin
admin_password = 123456
</code></pre>

<p>创建相应目录</p>

<pre><code>mkdir -p /var/log/nova
mkdir -p /var/lib/nova/instances
</code></pre>

<h3>初始化数据库</h3>

<pre><code>nova-manage db sync
</code></pre>

<h3>启动服务</h3>

<pre><code># controller node
nova-api
nova-conductor
nova-network
nova-scheduler
noVNC/utils/nova-novncproxy --config-file /etc/nova/nova.conf --web `pwd`/noVNC/

# compute node
nova-compute
#nova-network
</code></pre>

<h3>创建Endpoint</h3>

<pre><code>keystone service-create --name=nova --type=compute --description="Nova Compute Service"
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |       Nova Compute Service       |
|      id     | e8f13ca5e3de451887059358cce1071a |
|     name    |               nova               |
|     type    |             compute              |
+-------------+----------------------------------+

keystone endpoint-create \
    --service-id=e8f13ca5e3de451887059358cce1071a \
    --publicurl='http://localhost:8774/v2/%(tenant_id)s' \
    --internalurl='http://localhost:8774/v2/%(tenant_id)s' \
    --adminurl='http://localhost:8774/v2/%(tenant_id)s'
+-------------+----------------------------------------+
|   Property  |                 Value                  |
+-------------+----------------------------------------+
|   adminurl  | http://localhost:8774/v2/%(tenant_id)s |
|      id     |    30c72b9d0d794fa79201bbdd2aa10fa8    |
| internalurl | http://localhost:8774/v2/%(tenant_id)s |
|  publicurl  | http://localhost:8774/v2/%(tenant_id)s |
|    region   |               regionOne                |
|  service_id |    e8f13ca5e3de451887059358cce1071a    |
+-------------+----------------------------------------+
</code></pre>

<h3>验证一下</h3>

<pre><code>$ nova-manage service list
Binary           Host                                 Zone             Status     State Updated_At
nova-conductor   precise64                            internal         enabled    :-)   2013-10-17 15:52:40
nova-network     precise64                            internal         enabled    :-)   2013-10-17 15:52:47
nova-scheduler   precise64                            internal         enabled    :-)   2013-10-17 15:52:43
nova-compute     precise64                            nova             enabled    :-)   2013-10-17 15:52:49

$ nova-manage version
2014.1
</code></pre>

<p><code>nova image-list</code>输出结果应该和<code>glance image-list</code>相同</p>

<pre><code>$ nova image-list
+--------------------------------------+------------+--------+--------+
| ID                                   | Name       | Status | Server |
+--------------------------------------+------------+--------+--------+
| 1a736b75-3e49-4fed-97f1-f3257a75b3b8 | test image | ACTIVE |        |
+--------------------------------------+------------+--------+--------+

$ glance image-list
+--------------------------------------+------------+-------------+------------------+------+--------+
| ID                                   | Name       | Disk Format | Container Format | Size | Status |
+--------------------------------------+------------+-------------+------------------+------+--------+
| 1a736b75-3e49-4fed-97f1-f3257a75b3b8 | test image | aki         | aki              | 1024 | active |
+--------------------------------------+------------+-------------+------------------+------+--------+
</code></pre>

<h3>配置网络</h3>

<p>将网卡设为<code>promiscuous mode</code></p>

<pre><code>ip link set eth0 promisc on
</code></pre>

<p>修改网卡配置<code>/etc/network/interfaces</code></p>

<pre><code># The loopback network interface
auto lo
iface lo inet loopback

# The primary network interface
auto eth0
iface eth0 inet dhcp

# Bridge network interface for VM networks
auto br100
iface br100 inet static
address 192.168.100.1
netmask 255.255.255.0
bridge_stp off
bridge_fd 0
</code></pre>

<p>增加桥接设备（取名<code>br100</code>）</p>

<pre><code>brctl addbr br100
/etc/init.d/networking restart
</code></pre>

<p>检查一下</p>

<pre><code>$ ifconfig
    br100     Link encap:Ethernet  HWaddr 36:31:ff:07:28:7b
              inet addr:192.168.100.1  Bcast:192.168.100.255  Mask:255.255.255.0
              inet6 addr: fe80::3431:ffff:fe07:287b/64 Scope:Link
              UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
              RX packets:0 errors:0 dropped:0 overruns:0 frame:0
              TX packets:9 errors:0 dropped:0 overruns:0 carrier:0
              collisions:0 txqueuelen:0
              RX bytes:0 (0.0 B)  TX bytes:706 (706.0 B)

    eth0      Link encap:Ethernet  HWaddr 08:00:27:88:0c:a6
              inet addr:10.0.2.15  Bcast:10.0.2.255  Mask:255.255.255.0
              inet6 addr: fe80::a00:27ff:fe88:ca6/64 Scope:Link
              UP BROADCAST RUNNING PROMISC MULTICAST  MTU:1500  Metric:1
              RX packets:677269 errors:0 dropped:0 overruns:0 frame:0
              TX packets:361734 errors:0 dropped:0 overruns:0 carrier:0
              collisions:0 txqueuelen:1000
              RX bytes:524297575 (524.2 MB)  TX bytes:25305754 (25.3 MB)

    lo        Link encap:Local Loopback
              inet addr:127.0.0.1  Mask:255.0.0.0
              inet6 addr: ::1/128 Scope:Host
              UP LOOPBACK RUNNING  MTU:16436  Metric:1
              RX packets:270140 errors:0 dropped:0 overruns:0 frame:0
              TX packets:270140 errors:0 dropped:0 overruns:0 carrier:0
              collisions:0 txqueuelen:0
              RX bytes:105663149 (105.6 MB)  TX bytes:105663149 (105.6 MB)

    virbr0    Link encap:Ethernet  HWaddr 32:d5:7b:ce:e5:b0
              inet addr:192.168.122.1  Bcast:192.168.122.255  Mask:255.255.255.0
              UP BROADCAST MULTICAST  MTU:1500  Metric:1
              RX packets:0 errors:0 dropped:0 overruns:0 frame:0
              TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
              collisions:0 txqueuelen:0
              RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)
</code></pre>

<h3>创建虚机使用的网络</h3>

<pre><code>nova-manage network create private --fixed_range_v4=192.168.100.0/24 --bridge_interface=br100
</code></pre>

<h3>打开访问限制</h3>

<p>查看安全分组</p>

<pre><code>$ nova secgroup-list
+----+---------+-------------+
| Id | Name    | Description |
+----+---------+-------------+
| 1  | default | default     |
+----+---------+-------------+
</code></pre>

<p>放开SSH和ICMP（Ping）访问</p>

<pre><code>$ nova secgroup-add-rule default tcp 22 22 0.0.0.0/0
$ nova secgroup-add-rule default icmp -1 -1 0.0.0.0/0
$ nova secgroup-list-rules
</code></pre>

<blockquote><p>配置22端口后<code>vagrant ssh</code>可能无法访问，可使用VirtualBox的界面登录
然后可以根据需要安装图形界面，比如xfce: <code>apt-get install xubuntu-desktop; startx</code></p></blockquote>

<p>注入SSH公钥到虚机并确认（需要虚机Image支持）</p>

<pre><code>$ ssh-keygen -t rsa       # 一路回车
$ nova keypair-add --pub-key ~/.ssh/id_rsa.pub mykey

$ nova keypair-list
$ ssh-keygen -l -f ~/.ssh/id_rsa.pub
</code></pre>

<h3>打开<code>ip_v4</code>转发</h3>

<p>先看看是否已经打开</p>

<pre><code>$ sysctl net.ipv4.ip_forward
net.ipv4.ip_forward = 0
</code></pre>

<p>临时开启</p>

<pre><code>$ sysctl -w net.ipv4.ip_forward=1
</code></pre>

<p>永久开启，先编辑<code>/etc/sysctl.conf</code></p>

<pre><code>net.ipv4.ip_forward = 1
</code></pre>

<p>再重启服务</p>

<pre><code>/etc/init.d/procps restart  
</code></pre>

<h3>运行虚机实例</h3>

<p>先确认所有服务都在运行(<code>libvirtd</code>,<code>nova-api</code>,<code>nova-scheduler</code>,<code>nova-compute</code>,<code>nova-network</code>)</p>

<pre><code>$ ps -ef | grep libvirt
root     19970     1  0 14:04 ?        00:00:05 /usr/sbin/libvirtd -d

$ nova-manage service list
Binary           Host                                 Zone             Status     State Updated_At
nova-conductor   precise64                            internal         enabled    :-)   2013-10-17 15:52:40
nova-network     precise64                            internal         enabled    :-)   2013-10-17 15:52:47
nova-scheduler   precise64                            internal         enabled    :-)   2013-10-17 15:52:43
nova-compute     precise64                            nova             enabled    :-)   2013-10-17 15:52:49
</code></pre>

<p>启动实例</p>

<pre><code>$ nova secgroup-list
+----+---------+-------------+
| Id | Name    | Description |
+----+---------+-------------+
| 1  | default | default     |
+----+---------+-------------+

$ nova flavor-list 
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| ID | Name      | Memory_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor | Is_Public |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| 1  | m1.tiny   | 512       | 1    | 0         |      | 1     | 1.0         | True      |
| 2  | m1.small  | 2048      | 20   | 0         |      | 1     | 1.0         | True      |
| 3  | m1.medium | 4096      | 40   | 0         |      | 2     | 1.0         | True      |
| 4  | m1.large  | 8192      | 80   | 0         |      | 4     | 1.0         | True      |
| 5  | m1.xlarge | 16384     | 160  | 0         |      | 8     | 1.0         | True      |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+

$ nova image-list
+--------------------------------------+--------------+--------+--------+
| ID                                   | Name         | Status | Server |
+--------------------------------------+--------------+--------+--------+
| 5ef6d78b-dd3e-4575-ad52-692552f3ddd3 | Cirros 0.3.0 | ACTIVE |        |
+--------------------------------------+--------------+--------+--------+

$ nova boot --flavor 1 --image 5ef6d78b-dd3e-4575-ad52-692552f3ddd3 --security_group default cirros
</code></pre>

<p>查看实例状态(启动需要一些时间)</p>

<pre><code>$ nova list 
+--------------------------------------+--------+--------+------------+-------------+-----------------------+
| ID                                   | Name   | Status | Task State | Power State | Networks              |
+--------------------------------------+--------+--------+------------+-------------+-----------------------+
| 2c0c5c9b-2511-4616-8186-3843b0800da1 | cirros | BUILD  | spawning   | NOSTATE     | private=192.168.100.2 |
+--------------------------------------+--------+--------+------------+-------------+-----------------------+

$ nova list 
+--------------------------------------+--------+--------+------------+-------------+-----------------------+
| ID                                   | Name   | Status | Task State | Power State | Networks              |
+--------------------------------------+--------+--------+------------+-------------+-----------------------+
| 2c0c5c9b-2511-4616-8186-3843b0800da1 | cirros | ACTIVE | None       | Running     | private=192.168.100.2 |
+--------------------------------------+--------+--------+------------+-------------+-----------------------+
</code></pre>

<p>查看引导信息</p>

<pre><code>$ nova console-log cirros
...
Oct 17 10:02:00 cirros kern.info kernel: [    6.980753] ip_tables: (C) 2000-2006 Netfilter Core Team
Oct 17 10:02:13 cirros kern.debug kernel: [   19.977012] eth0: no IPv6 routers present
Oct 17 10:03:29 cirros authpriv.info dropbear[301]: Running in background
############ debug end   ##############
  ____               ____  ____
 / __/ __ ____ ____ / __ \/ __/
/ /__ / // __// __// /_/ /\ \ 
\___//_//_/  /_/   \____/___/ 
   http://cirros-cloud.net


login as 'cirros' user. default password: 'cubswin:)'. use 'sudo' for root.
cirros login: 
</code></pre>

<p>虚机应该可以Ping通，然后SSH登陆（密码：<code>cubswin:)</code>），从虚机可以Ping通公网IP</p>

<pre><code>ssh cirros@192.168.100.2
</code></pre>

<blockquote><p>并非每次都能Ping通，可以不停的删除后再重建，有时Ping通后过会儿又不行了，尚不清楚原因</p></blockquote>

<p>如果要删除虚机，执行（貌似需要执行两次，第一次修改状态，第二次移除）</p>

<pre><code>nova delete 2c0c5c9b-2511-4616-8186-3843b0800da1
</code></pre>

<h2>安装Horizon</h2>

<p>获取源码</p>

<pre><code># commit 1f7d703730d62c5e3896661a76a9808ec765ae1a
git clone https://github.com/openstack/horizon.git
</code></pre>

<p>安装</p>

<pre><code>cd horizon
pip install -r requirements.txt
python setup.py install
cd ..
</code></pre>

<p>创建配置文件</p>

<pre><code>cd horizon/openstack_dashboard/local
cp local_settings.py.example local_settings.py
cd -
</code></pre>

<p>修改配置<code>local_settings.py</code></p>

<pre><code>OPENSTACK_HOST = "127.0.0.1"
OPENSTACK_KEYSTONE_DEFAULT_ROLE = "admin"
</code></pre>

<p>启动</p>

<pre><code>cd horizon
./manage.py runserver 0.0.0.0:8888
</code></pre>

<blockquote><p>随便找个未被占用的端口即可</p>

<p>如果使用Vagrant，到Virtualbox的网络设置中加个端口映射即可从Host访问</p></blockquote>

<p>创建一个默认角色<code>Member</code>（否则“项目”页面的操作会报错）</p>

<pre><code>keystone role-create --name Member
</code></pre>

<h1>Troubleshooting</h1>

<h2>Expecting an auth URL via either --os-auth-url or env[OS_AUTH_URL]</h2>

<p>缺少环境变量，使用<code>admin_token</code>验证方式设置如下（<code>SERVICE_TOKEN</code>的值取自<code>/etc/keystone/keystone.conf</code>的<code>admin_token</code>字段）</p>

<pre><code>export SERVICE_TOKEN=ADMIN
export SERVICE_ENDPOINT=http://127.0.0.1:35357/v2.0/
</code></pre>

<p>或者创建用户的环境变量快速设置脚本，并运行</p>

<pre><code>cat &gt; ~/keystonerc_joe &lt;&lt; EOF
export OS_USERNAME=joe
export OS_TENANT_NAME=trial
export OS_PASSWORD=123123
export OS_AUTH_URL=http://127.0.0.1:5000/v2.0/
export PS1="[\u@\h \W(keystone_joe)]\$ "
EOF

. ~/keystonerc_joe
</code></pre>

<p>注：管理员端口为<code>35357</code>，普通用户是<code>5000</code>，参考<code>/etc/keystone/keystone.conf</code>的配置</p>

<h2>Unable to authorize user</h2>

<p>可能是数据库中不存在<code>identity</code>这个<code>endpoint</code>, 且<code>/etc/keystone/keystone.conf</code>又配置为从数据读取</p>

<pre><code>[catalog]
driver = keystone.catalog.backends.sql.Catalog
# driver = keystone.catalog.backends.templated.TemplatedCatalog
# template_file = default_catalog.templates
</code></pre>

<p>可配置为从模板读取</p>

<pre><code>[catalog]
# driver = keystone.catalog.backends.sql.Catalog
driver = keystone.catalog.backends.templated.TemplatedCatalog
template_file = default_catalog.templates
</code></pre>

<p>如果一定要从数据库读取，先增加<code>admin_token</code>方式验证的环境变量，然后手动增加endpoint信息，可参考<code>/etc/keystone/default_catalog.templates</code></p>

<h2>[swift, pip install -r reuqirements.txt] ERROR： "c/_cffi_backend.c:14:17: fatal error: ffi.h: No such file or directory"</h2>

<p>注释掉<code>requirements.txt</code>中的<code>xattr</code>,安装完依赖后自己手动安装<code>python-xattr</code>包</p>

<pre><code>pip install -r requirements.txt
apt-get install python-xattr
</code></pre>

<h2>[swift-init all start] ERROR: "NameError: name '_' is not defined"</h2>

<p><code>/usr/local/lib/python2.7/dist-packages/keystone/exception.py</code> 增加：</p>

<pre><code>import gettext
_ = gettext.gettext
</code></pre>

<h2>No module named swift_auth</h2>

<p><code>/etc/swift/proxy-server.conf</code> 修改：</p>

<pre><code>[filter:keystone]
# paste.filter_factory = keystone.middleware.swift_auth:filter_factory
use = egg:swift#keystoneauth
</code></pre>

<h2>[swift list] Endpoint for object-store not found</h2>

<p>如果<code>/etc/keystone/proxy-server.conf</code>配置为从模版读取,那么必须手动添加<code>endpoint</code>到模版，数据库创建语句无效。</p>

<pre><code>[catalog]
# dynamic, sql-based backend (supports API/CLI-based management commands)
#driver = keystone.catalog.backends.sql.Catalog

# static, file-based backend (does *NOT* support any management commands)
driver = keystone.catalog.backends.templated.TemplatedCatalog

template_file = default_catalog.templates
</code></pre>

<p><code>/etc/keystone/default_catalog.templates</code> 增加:</p>

<pre><code>catalog.RegionOne.object-store.publicURL = http://localhost:8080/v1/AUTH_$(tenant_id)s
catalog.RegionOne.object-store.adminURL = http://localhost:8080/v1/AUTH_$(tenant_id)s
catalog.RegionOne.object-store.internalURL = http://localhost:8080/v1/AUTH_$(tenant_id)s
catalog.RegionOne.object-store.name = Object Store Service
</code></pre>

<h2>[swift-init all start] Unable to locate config for object-expirer</h2>

<p><code>/etc/swift/object-server.conf</code> 增加：</p>

<pre><code>[object-expirer]
</code></pre>

<p>新建<code>/etc/swift/object-expirer.conf</code></p>

<pre><code>cat &gt; /etc/swift/object-expirer.conf &lt;&lt; EOF
[DEFAULT]

[object-expirer]
interval = 300

[pipeline:main]
pipeline = catch_errors cache proxy-server

[app:proxy-server]
use = egg:swift#proxy

[filter:cache]
use = egg:swift#memcache

[filter:catch_errors]
use = egg:swift#catch_errors
EOF
</code></pre>

<p>设置权限</p>

<pre><code>chown -R swift:swift /etc/swift
</code></pre>

<h2>[swift-init all start] Unable to locate config for proxy-server</h2>

<p>缺少<code>/etc/swift/proxy-server.conf</code>文件</p>

<h2>[Log] No such file or directory: '/var/cache/swift/object.recon'</h2>

<p><code>proxy-server.conf</code>增加：</p>

<pre><code>[filter:recon]
use = egg:swift#recon
recon_cache_path = /var/cache/swift

mkdir /var/cache/swift
chmod 777 /var/cache/swift
</code></pre>

<h2>[glance-control api start] __init__() got an unexpected keyword argument 'parents'</h2>

<pre><code>pip freeze | grep oslo
# oslo.config==1.2.0a3

pip uninstall oslo.config
pip install oslo.config==1.1.0
</code></pre>

<h2>没有glance命令</h2>

<p><code>glance</code>命令在包<code>glanceclient</code>中，该包是独立的，可以直接用<code>pip</code>快速安装：</p>

<pre><code>pip install python-glanceclient
</code></pre>

<h2>[glance add] Authorization Failed: *** (HTTP Unable to establish connection to http://127.0.0.1:35357/v2.0/tokens)</h2>

<p>确认keystone服务是否启动</p>

<pre><code>ps -Af | grep keystone
keystone-all &amp;
</code></pre>

<h2>[glance add] Authorization Failed: *** (HTTP Unable to establish connection to https://127.0.0.1:35357/v2.0/tokens)</h2>

<p>注意，这里的报错是<code>https</code>，检查配置文件<code>/etc/glance/glance-api.conf</code></p>

<pre><code># Valid schemes are 'http://' and 'https://'
# If no scheme specified,  default to 'https://'
swift_store_auth_address = http://127.0.0.1:35357/v2.0/
</code></pre>

<p>注意注释部分，如果没有<code>http://</code>则默认使用<code>https://</code></p>

<h2>[glance add] code 400, message Bad HTTP/0.9 request type</h2>

<p>启动命令换成如下，可看到日志错误提示信息：</p>

<pre><code>glance-api --config-file /etc/glance/glance-api.conf
glance-registry --config-file /etc/glance/glance-registry.conf
</code></pre>

<h2>[swift upload] 404 Not Found. The resource could not be found.</h2>

<p><code>chown -R swift:swift /srv/node</code>  (目录写权限问题)</p>

<h2>[glance index] WARNING keystone.common.controller [-] RBAC: Bypassing authorization</h2>

<p>可能是用admin验证引起的（启动方式<code>glance-control api/registry start</code>）</p>

<p>也可能是启动方式问题，使用<code>glance-api</code>和<code>glance-registry</code>启动后消失</p>

<h2>[glance add, /var/log/glance/api.log] Container HEAD failed: http://localhost:8080/v1/AUTH_9cb8bbc75bdb4484af790cfc3e4343e5/glance 404 Not Found</h2>

<p>swift中没有<code>glance</code>这个container，可以手动创建，也可以修改配置<code>/etc/glance/glance-api.conf</code></p>

<pre><code>swift_store_container = glance

# Do we create the container if it does not exist?
swift_store_create_container_on_put = True
</code></pre>

<h2>[glance-api --config-file /etc/glance/glance-api.conf] Stderr: '/bin/sh: 1: collie: not found\n'</h2>

<pre><code>apt-get install sheepdog
</code></pre>

<h2>[glance add] ClientException: Unauthorised. Check username, password and tenant name/id</h2>

<p>账户设置有问题，可以检查配置<code>/etc/glance/glance-api.conf</code>，也可以在报错文件的语句前插入打印语句查看</p>

<pre><code>swift_store_auth_address = http://127.0.0.1:35357/v2.0/
swift_store_user = admin:admin
swift_store_key = 123456
</code></pre>

<h2>[glance image-list] HTTPInternalServerError (HTTP 500)</h2>

<ul>
<li>确认安装<code>curl</code>。加上<code>-d</code>参数，可看到执行了<code>curl</code>命令，手动执行后报错<code>The program 'curl' is currently not installed.</code></li>
<li>确认<code>glance db_sync</code>执行成功。查看数据库<code>glance</code>，发现没有表，检查<code>glance-*.conf</code>的<code>sql-connection</code>配置</li>
<li>确认<code>glance-api.conf</code>文件中的<code>swift_store_auth_address = http://127.0.0.1:35357/v2.0/</code>是<code>http</code></li>
</ul>


<h2>[nova, pvcreate /dev/loop2] Device /dev/loop2 not found (or ignored by filtering)</h2>

<p>可能是修改了<code>/etc/lvm/lvm.conf</code>中的<code>filter</code>造成的</p>

<h2>[cinder create] ERROR cinder.scheduler.filters.capacity_filter [***] Free capacity not set: volume node info collection broken.</h2>

<h2>[cinder create] ERROR cinder.volume.flows.create_volume [***] Failed to schedule_create_volume: No valid host was found.</h2>

<p>使用<code>cinder-all</code>启动所有服务，然后<code>cinder create</code>时会就遇到这个报错；</p>

<p>使用如下启动方式时正常：</p>

<pre><code>cinder-volume --config-file=/etc/cinder/cinder.conf
cinder-api --config-file=/etc/cinder/cinder.conf
cinder-scheduler  --config-file=/etc/cinder/cinder.conf
</code></pre>

<h2>[cinder list] <code>Status</code>一直都是<code>creating</code></h2>

<pre><code>cinder list
+--------------------------------------+----------+--------------+------+-------------+----------+-------------+
|                  ID                  |  Status  | Display Name | Size | Volume Type | Bootable | Attached to |
+--------------------------------------+----------+--------------+------+-------------+----------+-------------+
| fbda9189-26e2-4e42-9622-f707be57d565 | creating |     test     |  1   |     None    |  False   |             |
+--------------------------------------+----------+--------------+------+-------------+----------+-------------+
</code></pre>

<p>首先确定数据库<code>cinder</code>中是否有表，即确保<code>cinder-manage db sync</code>执行成功</p>

<h2>[cinder create] <code>Status</code>是<code>error</code>，<code>cinder-volume</code>报错：<code>Exit code: 5</code></h2>

<p>确定配置文件<code>/etc/cinder/cinder.conf</code>包含如下内容</p>

<pre><code>state_path=/var/lib/cinder
volumes_dir=$state_path/volumes
</code></pre>

<h2>[cinder-volume] AMQP server on localhost:5672 is unreachable</h2>

<p>在不使用nova的情况下，确认<code>/etc/cinder/cinder.conf</code></p>

<pre><code>rabbit_virtual_host=/
</code></pre>

<h2>[nova-compute] ImportError: No module named libvirt</h2>

<pre><code>apt-get install python-libvirt
</code></pre>

<h2>[nova-api] Address already in use</h2>

<p>先确定是否已经有<code>nova-api</code>进程在运行</p>

<pre><code>ps -ef | grep nova
</code></pre>

<p>如果没有，杀掉占用<code>8777</code>的进程</p>

<pre><code>netstat -apn | grep 8777
</code></pre>

<h2>[nova image-list] ERROR: printt</h2>

<p><code>novaclient</code>代码有bug，修改<code>/usr/lib/python2.7/dist-packages/novaclient/utils.py</code></p>

<pre><code>def print_list(objs, fields, formatters={}):
    //此处省略N行
    print pt.get_string(sortby=fields[0])
    #pt.printt(sortby=fields[0])
</code></pre>

<p>安装<code>novnc</code>会作为依赖安装<code>novaclient</code>包，如果比较早的版本可能会有问题，用如下方式安装</p>

<pre><code>apt-get download novnc
dpkg --force-all -i novnc_*.deb
</code></pre>

<h2>[nova image-list] ERROR: Unauthorized (HTTP 401)</h2>

<p>修改<code>/etc/nova/api-paste.ini</code></p>

<pre><code>[filter:authtoken]
admin_tenant_name = admin
admin_user = admin
admin_password = 123456
</code></pre>

<h2>[nova net-list] ERROR: HTTPConnectionPool(host='10.0.2.15', port=8774): Max retries exceeded with url: /v2/dd3d73c9f6e64acca28376d9bad0fc58/os-tenant-networks (Caused by <class 'socket.error'>: [Errno 111] Connection refused)</h2>

<p>使用<code>devstack</code>在虚拟机安装后，执行<code>nova net-list</code>报错，执行<code>netstat</code>查看<code>8774</code>端口没有被监听，然后发现<code>nova-api</code>没有起来，手动启动后报错<code>OSError: [Errno 12] Cannot allocate memory</code>，当前虚拟及内存只分配了1G，扩大到2G后正常。</p>

<h2>[nova-compute] libvirtError: internal error Cannot find suitable emulator for x86_64</h2>

<pre><code>apt-get install guestmount
</code></pre>

<h2>[Ping] 虚机Ping不通</h2>

<ul>
<li>确认打开SSH和ICMP访问限制</li>
<li>确认打开ip_v4转发</li>
<li>确认<code>nova.conf</code>配置<code>use_ipv6=false</code></li>
<li>参考链接：<a href="https://ask.openstack.org/en/question/120/cantt-ping-my-vm-from-controller-node/">https://ask.openstack.org/en/question/120/cantt-ping-my-vm-from-controller-node/</a></li>
</ul>


<h2>[创建项目] NotFound: ***"Member"</h2>

<p>Horizon的“项目”页面点击“创建项目”按钮报错，因为缺少默认角色<code>Member</code>，创建即可</p>

<pre><code>keystone role-create --name Member
</code></pre>

  </section>
  
</article>


<section id="page_nav">
  
  
  <a href='/2013/09/27/git'>Next →</a>
  
</section>



        </div>
        <footer>
          <div>
            &copy; 2013 ~ 2015 Eric Zhong | powered by jekyll | themed by <a href="http://jiangle.name" title="jiangle">jiangle</a> | fork <a href="https://github.com/ericzhong/blog" title="fork me">me</a>
          </div>
        </footer>
      </div> <!-- main -->
  </body>
</html>

